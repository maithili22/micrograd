
# Micrograd

Micrograd is a simple implementation of a tiny neural network library designed to help understand the core concepts of backpropagation and neural networks. This project is built from scratch in Python, with a focus on educational purposes and gaining a deeper understanding of the underlying mechanics of neural networks.

## Features

- **Manual Backpropagation**: Implemented from the ground up to provide an intuitive understanding of how gradients are computed and propagated.
- **Basic Neural Network Components**: Includes essential components like neurons, layers, and activation functions.
- **Minimalistic Codebase**: The code is kept as simple and minimal as possible to focus on the key concepts without unnecessary complexity.
- **Educational Focus**: Great for those who want to learn how neural networks work under the hood.
